{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLg+vI7Oc40SuomKp7ADMs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumyajitcodes/Book-Store-Inventory-Management/blob/master/week4_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "from cvxopt import solvers\n",
        "import cvxopt.solvers                  # cvxopt for solving the dual optimization problem\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "UmuHtha90AdK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./pulsar_star_dataset.csv')\n",
        "df.head()                                                           # reading the dataset\n",
        "\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']                                                                                     # splitting the dataset into features and labels\n",
        "X = X.to_numpy()\n",
        "y = y.to_numpy()                                                                                    # converting the dataset into numpy array for ease of use\n",
        "y[y == 0] = -1                                                                                      # converting the labels to -1 and 1, as per the SVM problem formulation\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)           # splitting the dataset into train and test set\n",
        "mean_train = X_train.mean()                                                                         # standardizing the dataset\n",
        "std_train = X_train.std()"
      ],
      "metadata": {
        "id": "exyQA8Sg0HF1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_normalized = (X_train - mean_train)/std_train\n",
        "X_test_normalized = (X_test - mean_train)/std_train"
      ],
      "metadata": {
        "id": "GJGwgRgV0S5L"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SVM(object):\n",
        "\n",
        "    def linear_kernel(self, x1, x2):                                                            # defining the kernel functions, using numpy vectorisation to speed up the process\n",
        "        #########################################    code to be filled a(ii)\n",
        "        np.dot(x1, x2)                                                             # Fill up this '-----------' section\n",
        "        ###############################              End\n",
        "\n",
        "    def __init__(self, kernel_str='linear', C=1.0, gamma=0.1):                                 # initializing the SVM class\n",
        "        if kernel_str == 'linear':\n",
        "            self.kernel = SVM.linear_kernel\n",
        "        else:\n",
        "            self.kernel = SVM.linear_kernel\n",
        "            print('Invalid kernel string, defaulting to linear.')\n",
        "        self.C = C\n",
        "        self.gamma = gamma\n",
        "        self.kernel_str = kernel_str\n",
        "        if self.C is not None: self.C = float(self.C)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        num_samples, num_features = X.shape\n",
        "        kernel_matrix = np.zeros((num_samples, num_samples))                                                    # creating the kernel matrix\n",
        "        kernel_matrix = self.kernel(self, X, X.T)\n",
        "\n",
        "        P = cvxopt.matrix(np.outer(y,y) * kernel_matrix)                                                    # creating the matrices for the dual optimization problem, derivation explained in report\n",
        "        q = cvxopt.matrix(np.ones(num_samples) * -1)\n",
        "        A = cvxopt.matrix(y, (1,num_samples)) * 1.\n",
        "        b = cvxopt.matrix(0) * 1.\n",
        "        G_upper = np.diag(np.ones(num_samples) * -1)\n",
        "        G_lower = np.identity(num_samples)\n",
        "        G = cvxopt.matrix(np.vstack((G_upper, G_lower)))\n",
        "        h_upper = np.zeros(num_samples)\n",
        "        h_lower = np.ones(num_samples) * self.C\n",
        "        h = cvxopt.matrix(np.hstack((h_upper, h_lower)))\n",
        "\n",
        "        solvers.options['show_progress'] = False                                                            # turning off the progress bar of cvxopt\n",
        "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)                                                      # running the qp solver of cvxopt to solve the dual optimization problem\n",
        "        a = np.ravel(solution['x'])                                                                         # get the lagrange multipliers from the solution\n",
        "        support_vectors = a > 1e-4                                                                          # get the support vectors which have non-zero lagrange multipliers\n",
        "        ind = np.arange(len(a))[support_vectors]                                                            # get the indices of the support vectors for the kernel matrix\n",
        "        self.a = a[support_vectors]                                                                         # storing the data of the solution in the svm object\n",
        "        self.support_vectors = X[support_vectors]\n",
        "        self.y_support_vectors = y[support_vectors]\n",
        "        #print(\"%d support vectors out of %d points\" % (len(self.a), num_samples))\n",
        "\n",
        "        self.b = 0                                                                                          # deriving the bias value by enforcing the constraint for b in the svm optimization problem\n",
        "        for n in range(len(self.a)):\n",
        "            self.b += self.y_support_vectors[n]\n",
        "            self.b -= np.sum(self.a * self.y_support_vectors * kernel_matrix[ind[n],support_vectors])\n",
        "        self.b /= len(self.a)\n",
        "\n",
        "        if self.kernel_str == 'linear':                                                                     # deriving the weights for the linear kernel\n",
        "            self.w = np.zeros(num_features)\n",
        "            for n in range(len(self.a)):\n",
        "                self.w += self.a[n] * self.y_support_vectors[n] * self.support_vectors[n]\n",
        "        else:\n",
        "            self.w = None                                                                                   # if the kernel is not linear, then the weights are not defined\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.kernel_str == 'linear':                                                                     # if linear, then the prediction is given by the linear combination of the support vectors\n",
        "            #########################################    code to be filled a(iii)\n",
        "            clf = SVM('linear', C=c_value)                                                        # Fill up this '----------' section\n",
        "            return  clf.predict(X)                                                             # Fill up this '----------' section\n",
        "            ##############################              End\n",
        "        else:\n",
        "            y_predict = np.sum(self.a * self.y_support_vectors * self.kernel(self, X, self.support_vectors.T), axis=1)  # if not linear, then the prediction is given by the kernel modification to the standard linear version\n",
        "            #########################################    code to be filled a(iv)\n",
        "            --------------------------                                                              # Fill up this '----------' section\n",
        "            --------------------------                                                              # Fill up this '----------' section\n",
        "            ##############################              End\n",
        "\n",
        "# note that running on the full dataset is very slow (3-4 hours), so uncomment the code below and run this cell if you wish to check the results more quickly or apply grid search, comment it out again before running the full dataset\n",
        "X_train = X_train[:800]\n",
        "y_train = y_train[:800]\n",
        "X_test = X_test[:200]\n",
        "y_test = y_test[:200]"
      ],
      "metadata": {
        "id": "8TThAteG0TSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    \"\"\"\n",
        "    ALERT: * * * No changes are allowed in this section  * * *\n",
        "    \"\"\"\n",
        "\n",
        "    input_data_one = sys.argv[1].strip()\n",
        "\n",
        "    \"\"\"  Call to function that will perform the computation. \"\"\"\n",
        "    c_value = float(input_data_one)\n",
        "\n",
        "    svm_linear = SVM('linear', C=c_value)\n",
        "    svm_linear.fit(X_train, y_train)\n",
        "    y_pred_linear = svm_linear.predict(X_test)\n",
        "    print(accuracy_score(y_test, y_pred_linear))"
      ],
      "metadata": {
        "id": "NT2FgOp7DhW7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}